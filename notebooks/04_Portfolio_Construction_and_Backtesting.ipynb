{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38948795",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "- To translate the ML model's predictions into actionable trading signals and simulate their performance over historical data using a robust backtesting framework. This includes both deterministic and Monte Carlo backtesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c28c5",
   "metadata": {},
   "source": [
    "# Load Backtesting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af304b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "def load_backtest_inputs(\n",
    "    processed_dir=\"data/processed\",\n",
    "    metrics_dir=\"results/ml_metrics\",\n",
    "    backtest_config_path=\"config/backtest_config.yaml\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Load market data, ML features, and ML model predictions for the backtest period,\n",
    "    as well as backtesting parameters.\n",
    "    \"\"\"\n",
    "    # Load market data (example: all Parquet files in processed_dir)\n",
    "    market_data = {}\n",
    "    for fname in os.listdir(processed_dir):\n",
    "        if fname.endswith(\".parquet\") and \"test\" in fname:\n",
    "            key = fname.replace(\".parquet\", \"\")\n",
    "            market_data[key] = pd.read_parquet(os.path.join(processed_dir, fname))\n",
    "\n",
    "    # Load ML features (assuming features are part of the test parquet or separate)\n",
    "    # If separate, adjust logic accordingly\n",
    "\n",
    "    # Load ML model predictions\n",
    "    preds_path = os.path.join(metrics_dir, \"test_predictions.csv\")\n",
    "    if os.path.exists(preds_path):\n",
    "        predictions = pd.read_csv(preds_path)\n",
    "    else:\n",
    "        predictions = None\n",
    "        print(f\"Warning: Predictions file not found at {preds_path}\")\n",
    "\n",
    "    # Load backtesting parameters\n",
    "    with open(backtest_config_path, \"r\") as f:\n",
    "        backtest_config = yaml.safe_load(f)\n",
    "\n",
    "    return market_data, predictions, backtest_config\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    market_data, predictions, backtest_config = load_backtest_inputs()\n",
    "    print(\"Loaded market data keys:\", list(market_data.keys()))\n",
    "    if predictions is not None:\n",
    "        print(\"Loaded predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Signal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5484bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_trading_signals(predictions_df, \n",
    "                             long_threshold=0.01, \n",
    "                             short_threshold=-0.01,\n",
    "                             corporate_actions_df=None,\n",
    "                             index_rebalance_df=None,\n",
    "                             date_col='date',\n",
    "                             ticker_col='ticker'):\n",
    "    \"\"\"\n",
    "    Convert raw ML predictions into trading signals and apply event-driven logic.\n",
    "    \n",
    "    :param predictions_df: DataFrame with at least ['date', 'ticker', 'prediction']\n",
    "    :param long_threshold: float, minimum predicted return for a long signal\n",
    "    :param short_threshold: float, maximum predicted return for a short signal\n",
    "    :param corporate_actions_df: DataFrame with ['date', 'ticker', 'action'] (optional)\n",
    "    :param index_rebalance_df: DataFrame with ['date', 'ticker', 'rebalance_flag'] (optional)\n",
    "    :return: DataFrame with trading signals (1=long, -1=short, 0=flat)\n",
    "    \"\"\"\n",
    "    signals = predictions_df.copy()\n",
    "    # Basic signal rules\n",
    "    signals['signal'] = 0\n",
    "    signals.loc[signals['prediction'] > long_threshold, 'signal'] = 1\n",
    "    signals.loc[signals['prediction'] < short_threshold, 'signal'] = -1\n",
    "\n",
    "    # Event-driven logic: Avoid trades around corporate actions\n",
    "    if corporate_actions_df is not None:\n",
    "        corporate_actions_df[date_col] = pd.to_datetime(corporate_actions_df[date_col])\n",
    "        signals[date_col] = pd.to_datetime(signals[date_col])\n",
    "        merged = pd.merge(signals, corporate_actions_df[[date_col, ticker_col]], \n",
    "                          on=[date_col, ticker_col], how='left', indicator=True)\n",
    "        # If a corporate action is present, set signal to 0 (flat)\n",
    "        signals['signal'] = np.where(merged['_merge'] == 'both', 0, signals['signal'])\n",
    "\n",
    "    # Event-driven logic: Adjust for index rebalances (e.g., reduce position size or avoid trading)\n",
    "    if index_rebalance_df is not None:\n",
    "        index_rebalance_df[date_col] = pd.to_datetime(index_rebalance_df[date_col])\n",
    "        signals[date_col] = pd.to_datetime(signals[date_col])\n",
    "        merged = pd.merge(signals, index_rebalance_df[[date_col, ticker_col, 'rebalance_flag']],\n",
    "                          on=[date_col, ticker_col], how='left')\n",
    "        # Example: If rebalance_flag==1, halve the position size\n",
    "        signals['signal'] = np.where(merged['rebalance_flag'] == 1, signals['signal'] * 0.5, signals['signal'])\n",
    "\n",
    "    return signals\n",
    "\n",
    "# Example usage:\n",
    "# predictions = pd.read_csv(\"results/ml_metrics/test_predictions.csv\")\n",
    "# corp_actions = pd.read_csv(\"data/processed/corporate_actions.csv\")\n",
    "# index_reb = pd.read_csv(\"data/processed/index_rebalance_flags.csv\")\n",
    "# signals = generate_trading_signals(predictions, \n",
    "#                                    long_threshold=0.01, \n",
    "#                                    short_threshold=-0.01,\n",
    "#                                    corporate_actions_df=corp_actions,\n",
    "#                                    index_rebalance_df=index_reb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0c32b",
   "metadata": {},
   "source": [
    "# Deterministic Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from src.backtesting.backtester import Backtester\n",
    "from src.execution_sim.simulated_execution import execute_order\n",
    "\n",
    "def run_backtest_with_execution(\n",
    "    signals_df,\n",
    "    market_data_df,\n",
    "    backtest_config_path=\"config/backtest_config.yaml\"\n",
    "):\n",
    "    # Load backtest configuration\n",
    "    with open(backtest_config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    initial_cash = config.get(\"initial_cash\", 1_000_000)\n",
    "    transaction_cost = config.get(\"transaction_cost\", 0.001)\n",
    "    slippage = config.get(\"slippage\", 0.0005)\n",
    "    leverage = config.get(\"leverage\", 1.0)\n",
    "\n",
    "    # Initialize backtester\n",
    "    backtester = Backtester(\n",
    "        initial_cash=initial_cash,\n",
    "        transaction_cost=transaction_cost,\n",
    "        slippage=slippage\n",
    "    )\n",
    "\n",
    "    # Prepare logging\n",
    "    trade_log = []\n",
    "    portfolio_snapshots = []\n",
    "\n",
    "    # Ensure data is sorted by date\n",
    "    dates = sorted(signals_df['date'].unique())\n",
    "    for date in dates:\n",
    "        day_signals = signals_df[signals_df['date'] == date]\n",
    "        day_market = market_data_df[market_data_df['date'] == date]\n",
    "        prices = day_market.set_index('ticker')['close'].to_dict()\n",
    "        volumes = day_market.set_index('ticker')['volume'].to_dict()\n",
    "\n",
    "        # Execute trades for each ticker\n",
    "        for _, row in day_signals.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            signal = row['signal']\n",
    "            if ticker not in prices or np.isnan(prices[ticker]):\n",
    "                continue\n",
    "            # Determine order size (example: full notional, can be customized)\n",
    "            order_size = int((backtester.cash * leverage) // (prices[ticker] * (1 + transaction_cost)))\n",
    "            if signal == 1:\n",
    "                order_details = {\n",
    "                    'symbol': ticker,\n",
    "                    'side': 'buy',\n",
    "                    'size': order_size,\n",
    "                    'order_type': 'market'\n",
    "                }\n",
    "            elif signal == -1 and backtester.positions.get(ticker, 0) > 0:\n",
    "                order_details = {\n",
    "                    'symbol': ticker,\n",
    "                    'side': 'sell',\n",
    "                    'size': backtester.positions[ticker],\n",
    "                    'order_type': 'market'\n",
    "                }\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            current_market_data = {\n",
    "                'price': prices[ticker],\n",
    "                'volume': volumes.get(ticker, 0),\n",
    "                'bid': prices[ticker],\n",
    "                'ask': prices[ticker]\n",
    "            }\n",
    "            exec_result = execute_order(order_details, current_market_data)\n",
    "            trade_log.append({\n",
    "                'date': date,\n",
    "                'ticker': ticker,\n",
    "                'side': order_details['side'],\n",
    "                'size': exec_result['filled_size'],\n",
    "                'fill_price': exec_result['avg_fill_price'],\n",
    "                'slippage': exec_result['slippage']\n",
    "            })\n",
    "            # Update backtester positions and cash\n",
    "            if order_details['side'] == 'buy':\n",
    "                cost = exec_result['filled_size'] * exec_result['avg_fill_price'] * (1 + transaction_cost)\n",
    "                backtester.cash -= cost\n",
    "                backtester.positions[ticker] = backtester.positions.get(ticker, 0) + exec_result['filled_size']\n",
    "            elif order_details['side'] == 'sell':\n",
    "                proceeds = exec_result['filled_size'] * exec_result['avg_fill_price'] * (1 - transaction_cost)\n",
    "                backtester.cash += proceeds\n",
    "                backtester.positions[ticker] = 0\n",
    "\n",
    "        # Update portfolio value\n",
    "        backtester._update_portfolio_value(prices)\n",
    "        portfolio_snapshots.append({\n",
    "            'date': date,\n",
    "            'cash': backtester.cash,\n",
    "            'positions': dict(backtester.positions),\n",
    "            'portfolio_value': backtester.portfolio_value_history[-1]\n",
    "        })\n",
    "\n",
    "    # Save logs\n",
    "    pd.DataFrame(trade_log).to_csv(\"results/backtest_trade_log.csv\", index=False)\n",
    "    pd.DataFrame(portfolio_snapshots).to_csv(\"results/backtest_portfolio_snapshots.csv\", index=False)\n",
    "    print(\"Backtest complete. Trade log and portfolio snapshots saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example loading\n",
    "    signals = pd.read_csv(\"results/ml_metrics/test_predictions.csv\")  # Should have columns: date, ticker, signal\n",
    "    market_data = pd.read_parquet(\"data/processed/final_features_test.parquet\")  # Should have columns: date, ticker, close, volume\n",
    "    run_backtest_with_execution(signals, market_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Backtesting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe670bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from src.backtesting.monte_carlo_backtester import MonteCarloBacktester\n",
    "\n",
    "def load_backtest_config(config_path=\"config/backtest_config.yaml\"):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def historical_bootstrap_path_generator(market_data):\n",
    "    \"\"\"\n",
    "    Simple historical bootstrapping: randomly sample days with replacement.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    sampled_idx = np.random.choice(market_data.index, size=len(market_data), replace=True)\n",
    "    return market_data.loc[sampled_idx].reset_index(drop=True)\n",
    "\n",
    "def configure_and_run_monte_carlo(backtest_config, strategy_signals, market_data):\n",
    "    mc_cfg = backtest_config.get(\"monte_carlo\", {})\n",
    "    if not mc_cfg.get(\"enabled\", False):\n",
    "        print(\"Monte Carlo backtesting is not enabled in the config.\")\n",
    "        return\n",
    "\n",
    "    num_paths = mc_cfg.get(\"num_paths\", 100)\n",
    "    scenario_method = mc_cfg.get(\"scenario_method\", \"historical_bootstrap\")\n",
    "\n",
    "    # Select scenario generation method\n",
    "    if scenario_method == \"historical_bootstrap\":\n",
    "        path_generator = historical_bootstrap_path_generator\n",
    "    elif scenario_method == \"garch\":\n",
    "        from src.backtesting.monte_carlo_backtester import garch_path_generator\n",
    "        path_generator = garch_path_generator\n",
    "    elif scenario_method == \"pytorch_generative\":\n",
    "        from src.models.pytorch_models import generate_synthetic_paths\n",
    "        path_generator = generate_synthetic_paths\n",
    "    elif scenario_method == \"tensorflow_generative\":\n",
    "        from src.models.tensorflow_models import generate_synthetic_paths\n",
    "        path_generator = generate_synthetic_paths\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scenario method: {scenario_method}\")\n",
    "\n",
    "    mc_backtester = MonteCarloBacktester(backtester_config=mc_cfg.get(\"backtester_config\", {}))\n",
    "    results = mc_backtester.run_monte_carlo_simulations(\n",
    "        num_paths=num_paths,\n",
    "        path_generator=path_generator,\n",
    "        strategy_signals=strategy_signals,\n",
    "        market_data=market_data,\n",
    "        config=mc_cfg.get(\"backtester_config\", {})\n",
    "    )\n",
    "    print(f\"Monte Carlo simulation complete. Ran {num_paths} paths.\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    backtest_config = load_backtest_config()\n",
    "    # Load or define strategy_signals and market_data here\n",
    "    # strategy_signals = ...\n",
    "    # market_data = ...\n",
    "    # results = configure_and_run_monte_carlo(backtest_config, strategy_signals,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.backtesting.monte_carlo_backtester import MonteCarloBacktester\n",
    "import yaml\n",
    "\n",
    "def run_and_store_monte_carlo(\n",
    "    strategy_signals,\n",
    "    market_data,\n",
    "    backtest_config_path=\"config/backtest_config.yaml\",\n",
    "    results_dir=\"results/monte_carlo\"\n",
    "):\n",
    "    # Load config\n",
    "    with open(backtest_config_path, \"r\") as f:\n",
    "        backtest_config = yaml.safe_load(f)\n",
    "    mc_cfg = backtest_config.get(\"monte_carlo\", {})\n",
    "    num_paths = mc_cfg.get(\"num_paths\", 1000)\n",
    "    scenario_method = mc_cfg.get(\"scenario_method\", \"historical_bootstrap\")\n",
    "\n",
    "    # Select scenario generation method\n",
    "    if scenario_method == \"historical_bootstrap\":\n",
    "        def path_generator(md):\n",
    "            idx = np.random.choice(md.index, size=len(md), replace=True)\n",
    "            return md.loc[idx].reset_index(drop=True)\n",
    "    elif scenario_method == \"garch\":\n",
    "        from src.backtesting.monte_carlo_backtester import garch_path_generator\n",
    "        path_generator = garch_path_generator\n",
    "    elif scenario_method == \"pytorch_generative\":\n",
    "        from src.models.pytorch_models import generate_synthetic_paths\n",
    "        path_generator = generate_synthetic_paths\n",
    "    elif scenario_method == \"tensorflow_generative\":\n",
    "        from src.models.tensorflow_models import generate_synthetic_paths\n",
    "        path_generator = generate_synthetic_paths\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scenario method: {scenario_method}\")\n",
    "\n",
    "    # Run Monte Carlo simulations\n",
    "    mc_backtester = MonteCarloBacktester(backtester_config=mc_cfg.get(\"backtester_config\", {}))\n",
    "    results = mc_backtester.run_monte_carlo_simulations(\n",
    "        num_paths=num_paths,\n",
    "        path_generator=path_generator,\n",
    "        strategy_signals=strategy_signals,\n",
    "        market_data=market_data,\n",
    "        config=mc_cfg.get(\"backtester_config\", {})\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # Save equity curves\n",
    "    for i, eq_curve in enumerate(results['equity_curves']):\n",
    "        eq_curve.to_csv(os.path.join(results_dir, f\"equity_curve_{i+1}.csv\"))\n",
    "    # Save metrics\n",
    "    metrics_df = pd.DataFrame(results['metrics'])\n",
    "    metrics_df.to_csv(os.path.join(results_dir, \"monte_carlo_metrics.csv\"), index=False)\n",
    "    print(f\"Saved {num_paths} equity curves and metrics to {results_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load or define strategy_signals and market_data before running\n",
    "    # strategy_signals = ...\n",
    "    # market_data = ...\n",
    "    # run_and_store_monte_carlo(strategy_signals,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_deterministic_backtest_results(trade_log, position_log, equity_curve, output_dir=\"results/backtest_reports\"):\n",
    "    \"\"\"\n",
    "    Save trade logs, position logs, and equity curve to the specified directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trade_log.to_csv(os.path.join(output_dir, \"trade_log.csv\"), index=False)\n",
    "    position_log.to_csv(os.path.join(output_dir, \"position_log.csv\"), index=False)\n",
    "    equity_curve.to_csv(os.path.join(output_dir, \"equity_curve.csv\"), index=False)\n",
    "    print(f\"Deterministic backtest results saved to {output_dir}\")\n",
    "\n",
    "def save_monte_carlo_results(equity_curves, metrics_df, output_dir=\"results/monte_carlo_sims\"):\n",
    "    \"\"\"\n",
    "    Save all Monte Carlo equity curves and aggregated metrics to the specified directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save each equity curve\n",
    "    for i, eq_curve in enumerate(equity_curves):\n",
    "        eq_curve.to_csv(os.path.join(output_dir, f\"equity_curve_{i+1}.csv\"), index=False)\n",
    "    # Save metrics\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \"monte_carlo_metrics.csv\"), index=False)\n",
    "    print(f\"Monte Carlo simulation results saved to {output_dir}\")\n",
    "\n",
    "# Example usage:\n",
    "# save_deterministic_backtest_results(trade_log_df, position_log_df, equity_curve_df)\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
